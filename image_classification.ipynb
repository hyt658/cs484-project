{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UmLi2iCDfszJ"
      },
      "source": [
        "# **CS684 Project Report**\n",
        "\n",
        "Yutao (Frank) Han y326han@uwaterloo.ca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJ5tBjJzBNm"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The rapid growth of digital images in recent years has led to an increasing demand for effective and efficient image classification techniques. In many practical scenarios, however, acquiring a large amount of labeled data for training supervised classifiers can be difficult and expensive. This challenge has led to the development of semi-supervised learning approaches, which aim to leverage both labeled and unlabeled data to improve classification performance. In this report, we present a novel semi-supervised image classification method designed to benefit from unlabeled examples in the training dataset.\n",
        "\n",
        "Our project focuses on the problem of semi-supervised image classification, where only M out of N images in the training data have ground truth labels. We implement a weakly supervised training framework for a classification network that can exploit the information present in unlabeled examples. For our experiments, we use the standard dataset CIFAR-10 while ignoring labels on a subset of training examples. We investigate how the performance of our proposed method changes as M gets progressively smaller, shedding light on the effectiveness of our approach in low-label data scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoEg_73Mkfo"
      },
      "source": [
        "# Group Members and Contributions\n",
        "- Yutao (Frank) Han: y326han@uwaterloo.ca\n",
        "  - Contribute to the base code. Start up the fundemental Pseudo-Labelling structure training and create the basic CNN model\n",
        "  - Run experiments for Pseudo-Labelling\n",
        "  - Rearrange the codes, add comments and texts to improve the readability of the report\n",
        "- Renjie Ni: r6ni@uwaterloo.ca\n",
        "  - Contribute to the improvement of Pseudo-Labelling structure training, and build the Resnet-Kmeans structure and training.\n",
        "  - Run experiments for Pseudo-Labelling and Resnet-Kmeans\n",
        "  - Organize and analyze experimental results, and write the corresponding sections of the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTT_aM7R0txL"
      },
      "source": [
        "# Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMVEPyrMqui"
      },
      "source": [
        "We tried two different approaches to inplement the semi-supervised image classification:  Pseudo-Labelling model and Resnet-Kmeans model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-pBYETfMtXh"
      },
      "source": [
        "## Pseudo-Labelling(modified Teacher-student model)\n",
        "Firstly, we have chosen a relatively simple structure called pseudo-labeling. Its core idea is to utilize a model already trained on labeled data to predict the labels for unlabeled data. These predicted pseudo-labels are then combined with the true labels as training data to further train the model. To make our description more vivid and easier to understand, we prefer to call this model a modified teacher-student model where the teacher aims to train a student that surpasses its own performance using the unlabeled data. The student then becomes the new teacher, and the process is repeated. \n",
        "Here is the procedure for training:\n",
        "1. Create a `Teacher` model, train it with the labeled data.\n",
        "2. Use the `Teacher` model to predict the unlabled data and create pseudo-label for them (collect ones that above threshold).\n",
        "3. For each pseudo-label, we only chose the top 250 data with high probability.\n",
        "4. Create a `Student` model, train it with the predicted data.\n",
        "5. If `Student`'s performance is better than `Teacher`, then we use the this `Student` as next `Teacher` and repeat step 2-5. Also, it means that the prediction taht this `Student` made is strong confident, so we move the prediction of this time to labled data. Make sure they are removed from unlabled data to avoid repeating.\n",
        "6. The training will stop when the performance of `Student` doesn't improve a lot in a certain times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkJIGSHqMzgk"
      },
      "source": [
        "## Resnet-Kmeans\n",
        "The second model we have chosen is a semi-supervised model that combines ResNet and KMeans, which we call the ResNet-KMeans model. Unlike pseudo-labeling, which aims to expand the labeled dataset, its core idea is to combine the cross-entropy loss on labeled data points with the (unsupervised) K-means clustering loss over deep features (e.g., in the last layer before the linear classifier).\n",
        "\n",
        "Here is the procedure for training:\n",
        "\n",
        "1. Create a `supervised model` (ResNet) and train it with the labeled data.\n",
        "2. Extract the `deep features` (e.g., in the last layer before the linear classifier) and use them to train a `K-means model`.\n",
        "3. Combine the `cross-entropy loss` from ResNet and the `K-means clustering loss` to form a new loss.\n",
        "4. Perform `backward propagation` based on the new loss and update the supervised model.\n",
        "5. Repeat this procedure until the performance of the supervised model does not improve significantly within a certain number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6VSg-jM0xcB"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1po-Y8R1NoE"
      },
      "source": [
        "## Common codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOr_zEZUuDYL"
      },
      "source": [
        "Here are common codes including import definitions of class or functions used by both 2 methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd9Io-Pd3j2-"
      },
      "source": [
        "### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpjk5UQc3jCz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWRVMkgG1kFq"
      },
      "source": [
        "### Connected to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJhq8Mt8aXVn",
        "outputId": "a84f52fa-b8fa-4b46-f93d-98f4eef3f692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# For testing, you do not need to run this cell\n",
        "drive.mount('/content/drive')\n",
        "project_folder = \"/content/drive/MyDrive/cs484-project\"\n",
        "os.chdir(project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAXJLN3QOJyC"
      },
      "source": [
        "### Global variable settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UOJG4iHOJeV"
      },
      "outputs": [],
      "source": [
        "EPOCHES = 20\n",
        "BATCHES = 100\n",
        "WORKERS = 4\n",
        "\n",
        "MODEL_SAVE_PATH = \"./saved_model\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if not os.path.exists(MODEL_SAVE_PATH):\n",
        "    os.mkdir(MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX1hV6VKmCFq"
      },
      "source": [
        "### Definition of the CNN model\n",
        "We first try with normal CNN, but it does not have a very good performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A5aSSlQmFRc"
      },
      "outputs": [],
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(    \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc(x)\n",
        "        return x  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N93ldQzUmP9n"
      },
      "source": [
        "### Definition of Resnet\n",
        "We fianlly try ResNet to be the model for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aag8Q275mTeo"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.downsample(identity)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_blocks, num_classes=10):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.in_channels = 32\n",
        "      self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(32)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.layer1 = self.make_layer(BasicBlock, 32, num_blocks[0], stride=1)\n",
        "      self.layer2 = self.make_layer(BasicBlock, 64, num_blocks[1], stride=2)\n",
        "      self.layer3 = self.make_layer(BasicBlock, 128, num_blocks[2], stride=2)\n",
        "      self.layer4 = self.make_layer(BasicBlock, 256, num_blocks[3], stride=2)\n",
        "      self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "      self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        features = out.reshape(out.shape[0], -1)\n",
        "        \n",
        "        return features\n",
        "        \n",
        "\n",
        "    def features(self, x):\n",
        "        return self.forward_features(x)\n",
        "\n",
        "    def classifier(self, features):\n",
        "        return self.fc(features)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDC3Z2enmUeN"
      },
      "source": [
        "### Definition of CIFARData\n",
        "This class is created based on CIFAR-10 dataset. All images are size of 32x32. It has 50000 images for training and 10000 images for testing. We split the training images into two groups: one trains the model with label and the another one we ignore the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HkOFHKfqCEX"
      },
      "outputs": [],
      "source": [
        "class CIFARData():\n",
        "    def __init__(self, batch_size, num_workers, label_ratio):\n",
        "        cifar10_path = \"./data/cifar10\"\n",
        "        download = True\n",
        "        \n",
        "        # check if dataset has been downloaded\n",
        "        if os.path.isdir(os.path.join(cifar10_path, \"cifar-10-batches-py\")):\n",
        "            download = False\n",
        "\n",
        "        # Define the transforms for train data augmentation\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(24, padding=2),\n",
        "            transforms.RandomRotation(23),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            transforms.Resize(32, antialias=True)\n",
        "        ])\n",
        "\n",
        "        # Define the transforms for test data augmentation\n",
        "        test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            transforms.Resize(32, antialias=True)\n",
        "        ])\n",
        "\n",
        "        # obtain the train and test dataset\n",
        "        train_dataset = datasets.CIFAR10(root=cifar10_path, train=True, download=download, transform=train_transform)\n",
        "        test_dataset = datasets.CIFAR10(root=cifar10_path, train=False, download=download, transform=test_transform)\n",
        "\n",
        "        # shuffle the train_dataset to improve generalization\n",
        "        train_size = len(train_dataset)\n",
        "        train_indices = np.arange(train_size)\n",
        "        np.random.shuffle(train_indices)\n",
        "\n",
        "        # let 10% train data be the labeled, rest are unlabeled\n",
        "        split_pos = int(train_size * label_ratio)\n",
        "        labeled_train_indices = train_indices[:split_pos]\n",
        "        unlabeled_train_indices = train_indices[split_pos:]\n",
        "\n",
        "        # seperate the train_data set to labeled and unlabeled\n",
        "        labeled_dataset = Subset(train_dataset, labeled_train_indices)\n",
        "        unlabeled_dataset = Subset(train_dataset, unlabeled_train_indices)\n",
        "\n",
        "        labeled_train_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "        unlabeled_train_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        self.labeled_train_loader = labeled_train_loader\n",
        "        self.unlabeled_train_loader = unlabeled_train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a77t43I2O7Y"
      },
      "source": [
        "### Definition of CustomDataset\n",
        "This class is used for creating our own dataset (based on python list)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T_wMXUO2OOT"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "        self.data = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYB_1dbMRcuS"
      },
      "source": [
        "### Definition of CombinedDataset\n",
        "This class is used to combined labeled and unlabeled data. For unlabeled data, we return its label as -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xJaSTAARecl"
      },
      "outputs": [],
      "source": [
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, labeled_data, unlabeled_data):\n",
        "        self.labeled_data = labeled_data.dataset\n",
        "        self.unlabeled_data = unlabeled_data.dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.labeled_data):\n",
        "            return self.labeled_data[idx]\n",
        "        else:\n",
        "            data, _ = self.unlabeled_data[idx - len(self.labeled_data)]\n",
        "            return data, -1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data) + len(self.unlabeled_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WseLBLiRhAC"
      },
      "source": [
        "### Definition of some help functions\n",
        "1. listToDataloader: convert a list of tuple (data, label) to a Dataloader\n",
        "2. indiceSubsetDatalodaer: give dataloader, we extract the data indicated by indices and return a new dataloader\n",
        "3. concatDataloader: concat two dataloaders to form a new dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9wev61TRirS"
      },
      "outputs": [],
      "source": [
        "def listToDataloader(data_list, batch_size, num_workers):\n",
        "    dataset = CustomDataset(data_list)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "\n",
        "def indiceSubsetDatalodaer(dataloader, indices):\n",
        "    batch = dataloader.batch_size\n",
        "    worker = dataloader.num_workers\n",
        "\n",
        "    origin_dataset = dataloader.dataset\n",
        "    new_dataset = Subset(origin_dataset, indices)\n",
        "    dataloader = DataLoader(new_dataset, shuffle=True, batch_size=batch, num_workers=worker)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def concatDataloader(data1, data2, has_unlabel=False):\n",
        "    dataloader = None\n",
        "    batch = data1.batch_size\n",
        "    worker = data1.num_workers\n",
        "\n",
        "    if has_unlabel:\n",
        "        combined_data = CombinedDataset(data1.dataset, data2.dataset)\n",
        "        dataloader = DataLoader(combined_data, shuffle=True, batch_size=batch, num_workers=worker)\n",
        "    else:\n",
        "        combined_data = ConcatDataset([data1.dataset, data2.dataset])\n",
        "        dataloader = DataLoader(combined_data, shuffle=True, batch_size=batch, num_workers=worker)\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBUHPjfG4esB"
      },
      "source": [
        "### Definition of `train()`\n",
        "This function trains the model with given dataloader (data with label), criterion, and optimizer.       \\\n",
        "Return the best loss during training. Basically it's supervised training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIaQNp2yqE76"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, criterion, optimizer, epochs=20):\n",
        "    model.to(DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        best_train_loss = 0\n",
        "        curr_train_loss = 0\n",
        "        msg_len = 0\n",
        "\n",
        "        for batch_idx, (data, label) in enumerate(dataloader):\n",
        "            data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "            curr_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if ((batch_idx+1) % 10 == 0):\n",
        "                print(' ' * msg_len, end='\\r')      # clean current line\n",
        "                databatch_count = len(dataloader)\n",
        "                percent = float(batch_idx / databatch_count * 100)\n",
        "                msg = \"Epoch: {}, Progress: {}/{} ({:.1f}%)\".format(\n",
        "                    epoch+1, batch_idx+1, databatch_count, percent)\n",
        "                print(msg, end='\\r')\n",
        "                msg_len = len(msg)\n",
        "\n",
        "        data_count = len(dataloader.dataset)\n",
        "        curr_train_loss /= data_count\n",
        "        \n",
        "        if epoch == epochs - 1:\n",
        "          print(\"Loss on the training data: {}\".format((curr_train_loss)))\n",
        "\n",
        "        if (curr_train_loss < best_train_loss):\n",
        "            best_train_loss = curr_train_loss\n",
        "\n",
        "    return best_train_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOq7gUGT4oqN"
      },
      "source": [
        "### Definition of `test()`\n",
        "This function tests the model's performance with given dataloader and criterion.        \\\n",
        "Return the final test loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfpHuH6Z4sDm"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, criterion):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    print(\"Testing starts...\")\n",
        "    with torch.no_grad():\n",
        "        for data, label in dataloader:\n",
        "            data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "            test_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(label).sum()\n",
        "\n",
        "    data_count = len(dataloader.dataset)\n",
        "    test_loss /= data_count\n",
        "    accuracy = float(correct / data_count * 100)\n",
        "    print(\"Test result - Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\".format(\n",
        "        test_loss, correct, data_count, accuracy))\n",
        "    \n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KAUskNv4wNv"
      },
      "source": [
        "### Definition of `predict()`\n",
        "This function uses a model to predict the label for unlabeled data.         \\\n",
        "Return the dataloader of `(data, predicted label)` within given threshold and a list of indices of data that are not chosen as good prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qnHV7evPGuh"
      },
      "outputs": [],
      "source": [
        "def predict(model, dataloader, threshold):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    msg_len = 0\n",
        "\n",
        "    # result will be list of tuple (data, label)\n",
        "    result = []\n",
        "\n",
        "    # the indices of not predicting properly data in dataset\n",
        "    unused_indices = []\n",
        "\n",
        "    # sample_data is a dict of list, format is\n",
        "    #   label: [data_idx, probability of this data belongs to this label]\n",
        "    sample_data = defaultdict(list)\n",
        "\n",
        "    # predict the label by given model, for each data use its topk possible\n",
        "    #   label, then put them into sample_data\n",
        "    print(\"Prediction starts...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, _) in enumerate(dataloader):\n",
        "            data = data.to(DEVICE)\n",
        "\n",
        "            output = model(data)\n",
        "            softmax_output = F.softmax(output, dim=-1)\n",
        "            topk, topk_idx = softmax_output.topk(k=10, dim=1)\n",
        "\n",
        "            data = data.cpu()\n",
        "            topk = topk.cpu()\n",
        "            topk_idx = topk_idx.cpu()\n",
        "\n",
        "            for idx in range(topk_idx.size(0)):\n",
        "                has_good_pred = False\n",
        "                for i, label in enumerate(topk_idx[idx]):\n",
        "                    if topk[idx][i] > threshold:\n",
        "                        curr = data[idx]\n",
        "                        sample_data[label.item()].append((curr, topk[idx][i]))\n",
        "                        has_good_pred = True\n",
        "                if has_good_pred == False:\n",
        "                  curr_idx = batch_idx * BATCHES + idx\n",
        "                  unused_indices.append(curr_idx)\n",
        "\n",
        "    \n",
        "    # now base on sample_data, for each label, let the first 100\n",
        "    #   data (sort in probability) that own this label\n",
        "    print(\"\\nPacking prediction result...\", end='')\n",
        "    for label in sample_data:\n",
        "        sort_func = lambda x: x[1]  # x[1] is the probability\n",
        "        chosen = sorted(sample_data[label], key=sort_func, reverse=True)[:250]\n",
        "        for data_prob_pair in chosen:\n",
        "            result.append((data_prob_pair[0], label))\n",
        "    print(\"Done\\n\")\n",
        "\n",
        "    predict = listToDataloader(result, BATCHES, WORKERS)\n",
        "\n",
        "    return predict, unused_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l91D1QavmY0q"
      },
      "source": [
        "### Definition of getBestTeacher()\n",
        "Either load the saved best teacher model or train a new one.        \\\n",
        "Return the teacher model and its test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgEZPQO93XdS"
      },
      "outputs": [],
      "source": [
        "def getBestTeacher(is_train, label_data, test_data):\n",
        "    teacher = ResNet([2, 2, 2, 2])\n",
        "\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    teacher_path = os.path.join(MODEL_SAVE_PATH, \"best_teacher_model_{}.pt\".format(DEVICE))\n",
        "    find_save = os.path.exists(teacher_path)\n",
        "\n",
        "    if find_save:\n",
        "        # load from saved model\n",
        "        checkpoint = torch.load(teacher_path)\n",
        "\n",
        "    if not is_train:\n",
        "        # check if we have model saved\n",
        "        if not find_save:\n",
        "            print(\"Saved teacher model is not detected, start training a new one...\")\n",
        "            is_train = True\n",
        "        \n",
        "    if is_train:\n",
        "        # train teacher model\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(teacher.parameters(), lr=0.001)\n",
        "        print(\"Teacher starts to be trained with labeled data...\")\n",
        "        train_loss = train(teacher, label_data, criterion, optimizer)\n",
        "        test_loss, test_accuracy = test(teacher, test_data, criterion)\n",
        "\n",
        "        state = {\n",
        "            \"model\": teacher.state_dict(), \n",
        "            \"train_loss\": train_loss,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"accuracy\": test_accuracy\n",
        "        }\n",
        "\n",
        "        if find_save:\n",
        "            # if this train result is better, we update the old checkpoint\n",
        "            saved_accuracy = checkpoint[\"accuracy\"]\n",
        "            if (test_accuracy > saved_accuracy):\n",
        "                torch.save(state, teacher_path)\n",
        "        else:\n",
        "            # if no checkpoint, save one\n",
        "            torch.save(state, teacher_path)\n",
        "    else:\n",
        "        print(\"Load saved Teacher model...\")\n",
        "        teacher.load_state_dict(checkpoint[\"model\"])\n",
        "    \n",
        "    return teacher, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtAyWFeOPMQx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQQjzmi-6vDR"
      },
      "source": [
        "## Proof that our supervised model is good enough on the CIFARData\n",
        "We use all training data as label to show our model is suitable for CIFARData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBuZzvoR68f9",
        "outputId": "4b25abc9-52c8-430a-abd2-207cf71283e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.01624630845195115\n",
            "Epoch: 2, Loss: 0.012837725024030666\n",
            "Epoch: 3, Loss: 0.011498009484223646\n",
            "Epoch: 4, Loss: 0.010485120406054487\n",
            "Epoch: 5, Loss: 0.00970223133130507\n",
            "Epoch: 6, Loss: 0.009034303588096542\n",
            "Epoch: 7, Loss: 0.008509872717086715\n",
            "Epoch: 8, Loss: 0.008138865764694985\n",
            "Epoch: 9, Loss: 0.0077260920086292305\n",
            "Epoch: 10, Loss: 0.007438626713824995\n",
            "Epoch: 11, Loss: 0.007119861260207012\n",
            "Epoch: 12, Loss: 0.006918724930647648\n",
            "Epoch: 13, Loss: 0.006635727194222537\n",
            "Epoch: 14, Loss: 0.006465777035313423\n",
            "Epoch: 15, Loss: 0.006213168660799662\n",
            "Epoch: 16, Loss: 0.0061056578279745696\n",
            "Epoch: 17, Loss: 0.005908723353737533\n",
            "Epoch: 18, Loss: 0.005801944066779782\n",
            "Epoch: 19, Loss: 0.00561020906284602\n",
            "Epoch: 20, Loss: 0.005477223042285804\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0078, Accuracy: 7589/10000 (75.9%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "full_data = CIFARData(batch_size=BATCHES, num_workers=4, label_ratio=0.99)\n",
        "full_label_data = full_data.labeled_train_loader\n",
        "full_test_data = full_data.test_loader\n",
        "\n",
        "# full_model = ImageClassifierCNN()        # we tried the other CNN before but didn't show a good performance\n",
        "full_model = ResNet(num_blocks=[2, 2, 2, 2])\n",
        "full_optimizer = optim.Adam(full_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "full_model_loss = train(full_model, full_label_data, criterion, full_optimizer)\n",
        "full_test_loss, full_test_accuracy = test(full_model, full_test_data, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbgSq7Amf-o"
      },
      "source": [
        "## First experiment: Training with the Pseduo Labelling method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETAKtXwdTzNj"
      },
      "source": [
        "### Definition of `train_teacher_student` \n",
        "This function uses Pseudo-Labelling structure training method. `label_ratio` is the ratio of labeled data to entire CIFAR-10 training data, `save_student` decide if save final best student model and `identify` is for customizing the name of saved model. The name will be `best_student_model_{identify}.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpRSZp3uZ1Yy"
      },
      "outputs": [],
      "source": [
        "def train_teacher_student(label_ratio, save_student=True, identify=\"\"):\n",
        "    threshold = 0.9\n",
        "    acc_threshold = 0.3\n",
        "    stop_threshold = 3\n",
        "\n",
        "    dataloader = CIFARData(batch_size=BATCHES, num_workers=WORKERS, label_ratio=label_ratio)\n",
        "    label_data = dataloader.labeled_train_loader\n",
        "    unlabeled_data = dataloader.unlabeled_train_loader\n",
        "    test_data = dataloader.test_loader\n",
        "\n",
        "    # get teacher model\n",
        "    teacher, teacher_test_accuracy = getBestTeacher(is_train=True, label_data=label_data, test_data=test_data)\n",
        "\n",
        "    # initial variables for training loop\n",
        "    improved = True\n",
        "    stop_count = 0\n",
        "    count = 0\n",
        "\n",
        "    # collect the best student model\n",
        "    best_model = None\n",
        "    best_train_loss = torch.inf\n",
        "    best_test_loss = torch.inf\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # the indices of data in unlabeled data that didn't get well predicted\n",
        "    unused_indices = []\n",
        "\n",
        "    while improved:\n",
        "        # use teacher to predict unlabeled data, then take good predicted data out\n",
        "        print(\"Teacher starts to predict unlabeled data...\")\n",
        "        pred_data, unused_indices = predict(teacher, unlabeled_data, threshold)\n",
        "\n",
        "        # combined labeled and prediction data\n",
        "        combined_data = concatDataloader(label_data, pred_data)\n",
        "\n",
        "        # train the student with prediction data\n",
        "        student = ResNet([2, 2, 2, 2])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(student.parameters(), lr=0.0005)\n",
        "        print(\"Student starts to be trained with prediction data...\")\n",
        "        student_train_loss = train(student, combined_data, criterion, optimizer)\n",
        "        student_test_loss, student_test_accuracy = test(student, test_data, criterion)\n",
        "\n",
        "        # update the best student and model info\n",
        "        if student_test_accuracy > best_accuracy:\n",
        "            best_model = deepcopy(student)\n",
        "            best_train_loss = student_train_loss\n",
        "            best_test_loss = student_test_loss\n",
        "            best_accuracy = student_test_accuracy\n",
        "\n",
        "        # accuracy improvement calculation\n",
        "        accuracy_improvement = student_test_accuracy - teacher_test_accuracy\n",
        "\n",
        "        # if student is worse than teacher, we increase stop_count\n",
        "        if accuracy_improvement < acc_threshold:\n",
        "            stop_count += 1\n",
        "        else:\n",
        "            stop_count = 0\n",
        "\n",
        "        # if the performance  of the model has not been improved for several times, stop\n",
        "        if stop_count == stop_threshold:\n",
        "            improved = False\n",
        "        elif accuracy_improvement > acc_threshold:\n",
        "            # update teacher model to the better student model\n",
        "            teacher = deepcopy(student)\n",
        "            teacher_test_accuracy = student_test_accuracy\n",
        "\n",
        "            # since we use the new student as teacher, we move its good predicted unlabeled\n",
        "            #   data to labled\n",
        "            unlabeled_data = indiceSubsetDatalodaer(unlabeled_data, unused_indices)\n",
        "            label_data = combined_data\n",
        "\n",
        "        count += 1\n",
        "        threshold -= 0.005\n",
        "\n",
        "        if count == EPOCHES:\n",
        "            improved = False\n",
        "        \n",
        "    print(\"the final size of label_data is {}\".format((len(label_data.dataset))))\n",
        "    print(\"Best student accuracy is {}%\".format(best_accuracy))\n",
        "\n",
        "    if save_student:\n",
        "        if identify == \"\":\n",
        "          identify = str(label_ratio)\n",
        "\n",
        "        student_path = os.path.join(MODEL_SAVE_PATH, \"best_student_model_{}_{}.pt\".format(DEVICE, identify))\n",
        "        find_save = os.path.exists(student_path)\n",
        "        state = {\n",
        "            \"model\": best_model.state_dict(), \n",
        "            \"train_loss\": best_train_loss,\n",
        "            \"test_loss\": best_test_loss,\n",
        "            \"accuracy\": best_accuracy\n",
        "        }\n",
        "\n",
        "        # check if we have student saved. if does, compare the accuracy and save the best one\n",
        "        if (find_save):\n",
        "            checkpoint = torch.load(student_path)\n",
        "            saved_acc = checkpoint[\"accuracy\"]\n",
        "            if (best_accuracy > saved_acc):\n",
        "                torch.save(state, student_path)\n",
        "        else:\n",
        "            torch.save(state, student_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oldOvfvTs9M1"
      },
      "source": [
        "### Try Pseudo-Labelling method with `label_ratio=0.01`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vRn2g9qU0Hn"
      },
      "source": [
        "Since for label_ratio = 0.01, the size of labeled data is too small, and thus we changed the batch from 100 to 10 for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLNvKM7bs5tk",
        "outputId": "e179b587-9365-476a-bb37-c7ed35e86217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.011903762340545654\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0225, Accuracy: 3156/10000 (31.6%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.004685787918839946\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0215, Accuracy: 3436/10000 (34.4%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0026941951629212355\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0233, Accuracy: 3573/10000 (35.7%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0017671159415388136\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0233, Accuracy: 3623/10000 (36.2%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.00144469935931067\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0243, Accuracy: 3741/10000 (37.4%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.001061714297036958\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0253, Accuracy: 3493/10000 (34.9%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0010350502990288993\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0249, Accuracy: 3690/10000 (36.9%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0011028802980639829\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0279, Accuracy: 3518/10000 (35.2%)\n",
            "\n",
            "the final size of label_data is 6949\n",
            "Best student accuracy is 37.40999984741211%\n"
          ]
        }
      ],
      "source": [
        "BATCHES = 10\n",
        "train_teacher_student(label_ratio=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYMtUq9rqCZN"
      },
      "source": [
        "### Try Pseudo-Labelling method with `label_ratio=0.05`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S6W_pOYqG-J",
        "outputId": "87d91afc-41e3-4bd2-8ff0-db586779ff26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.01262520136833191\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0178, Accuracy: 4451/10000 (44.5%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.007459563621999938\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0173, Accuracy: 4914/10000 (49.1%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005345890304748854\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0159, Accuracy: 5313/10000 (53.1%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003957555261251691\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0224, Accuracy: 4576/10000 (45.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0038410417564223574\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0201, Accuracy: 4714/10000 (47.1%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003869880711794885\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0241, Accuracy: 4251/10000 (42.5%)\n",
            "\n",
            "the final size of label_data is 5948\n",
            "Best student accuracy is 53.130001068115234%\n"
          ]
        }
      ],
      "source": [
        "BATCHES = 100\n",
        "train_teacher_student(label_ratio=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY06ZjKVX6xG"
      },
      "source": [
        "### Try Pseudo-Labelling method with `label_ratio=0.1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDF3IyndPe2c",
        "outputId": "adf90e21-04a5-4f78-99aa-9e7c58dfd772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.011229814183712005\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0142, Accuracy: 5388/10000 (53.9%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.008048584062375921\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0142, Accuracy: 5389/10000 (53.9%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.007713436479689147\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0152, Accuracy: 5475/10000 (54.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005990117340561573\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0145, Accuracy: 5661/10000 (56.6%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.004756865850035756\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0153, Accuracy: 5782/10000 (57.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003945739393964022\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0136, Accuracy: 6023/10000 (60.2%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0034250929166495603\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0150, Accuracy: 5850/10000 (58.5%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003422005916403617\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0123, Accuracy: 6183/10000 (61.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0029655986301162663\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0148, Accuracy: 5835/10000 (58.3%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.002980615399246971\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0158, Accuracy: 5759/10000 (57.6%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0030586367897081235\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0152, Accuracy: 5921/10000 (59.2%)\n",
            "\n",
            "Best student accuracy is 61.829994201660156%\n"
          ]
        }
      ],
      "source": [
        "train_teacher_student(label_ratio=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnGC-dGbLxd"
      },
      "source": [
        "The final size of label_data is 15679."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlMce0tYZzGY"
      },
      "source": [
        "### Try Pseudo-Labelling method with `label_ratio=0.3`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SkSY976bIOW",
        "outputId": "630a584c-59e1-4f53-bf89-6009fb0f87da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.008263090761502584\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0126, Accuracy: 6178/10000 (61.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.006812994327007079\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0126, Accuracy: 6235/10000 (62.3%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005833890086168951\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0116, Accuracy: 6589/10000 (65.9%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.00543058670656827\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0097, Accuracy: 6967/10000 (69.7%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.004673091271874223\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0099, Accuracy: 7037/10000 (70.4%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.004307664530051728\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0102, Accuracy: 7107/10000 (71.1%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.004001441635508756\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0116, Accuracy: 6848/10000 (68.5%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003985174202889828\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0104, Accuracy: 6985/10000 (69.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.003943465147317438\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0118, Accuracy: 6815/10000 (68.1%)\n",
            "\n",
            "the final size of label_data is 27254\n",
            "Best student accuracy is 71.06999969482422%\n"
          ]
        }
      ],
      "source": [
        "train_teacher_student(label_ratio=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMhiWZxVbcfo"
      },
      "source": [
        "### Try Pseudo-Labelling method with `label_ratio=0.5`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUD0-I1Vba9i",
        "outputId": "72256791-c818-497b-b314-8616df1ca287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.007073681125640869\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0112, Accuracy: 6663/10000 (66.6%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.006416746939573615\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0113, Accuracy: 6605/10000 (66.0%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.006261858345380518\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0107, Accuracy: 6785/10000 (67.8%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005792191870955631\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0082, Accuracy: 7357/10000 (73.6%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005305755660251249\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0095, Accuracy: 7125/10000 (71.2%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.0054252318832597015\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0112, Accuracy: 6835/10000 (68.3%)\n",
            "\n",
            "Teacher starts to predict unlabeled data...\n",
            "Prediction starts...\n",
            "\n",
            "Packing prediction result...Done\n",
            "\n",
            "Student starts to be trained with prediction data...\n",
            "Loss on the training data: 0.005407552540612089\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0093, Accuracy: 7226/10000 (72.3%)\n",
            "\n",
            "the final size of label_data is 29849\n",
            "Best student accuracy is 73.56999206542969%\n"
          ]
        }
      ],
      "source": [
        "train_teacher_student(label_ratio=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjO6rw1pVSX8"
      },
      "source": [
        "## Second Experiemnt: Training with the Resnet-Kmeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU9fv7i8cqUO"
      },
      "source": [
        "### Definition of `kmeans_loss()`\n",
        "This function computes the loss of k-means based on given features and centroids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8W8cP6L-xjZ"
      },
      "outputs": [],
      "source": [
        "def kmeans_loss(features, centroids):\n",
        "    distances = torch.cdist(features, centroids)\n",
        "    min_distances, _ = torch.min(distances, dim=1)\n",
        "    loss = torch.mean(min_distances ** 2)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QUq7d1cVcFp"
      },
      "source": [
        "### Definition of `train_combined()`\n",
        "This function is to train the model for one epoch where the loss is the combination of Resnet cross-entropy and Kmeans clustering loss. Kmeans_weight decides the ratio of Kmeans clustering loss in the combined loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi4WshOgQOso"
      },
      "outputs": [],
      "source": [
        "def train_combined(model, dataloader, optimizer, criterion, device, kmeans_weight, num_classes):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    sup_loss = 0\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        labeled_mask = targets != -1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Get the output before the linear classifier\n",
        "        features = model.features(data)\n",
        "        \n",
        "        # Compute the K-means clustering loss\n",
        "        centroids = torch.randn(num_classes, features.size(1), device=device)\n",
        "        # centroids = initialize_centroids(features, num_classes)\n",
        "        kmeans_loss_value = kmeans_loss(features, centroids)\n",
        "        \n",
        "        # Compute the cross-entropy loss for labeled data\n",
        "        output = model.classifier(features)\n",
        "        ce_loss_value = 0\n",
        "        if labeled_mask.sum() > 0:\n",
        "            ce_loss_value = criterion(output[labeled_mask], targets[labeled_mask])\n",
        "        \n",
        "        # Combine the losses\n",
        "        loss = ce_loss_value + kmeans_weight * kmeans_loss_value\n",
        "        # print(\"ce_loss_value: \", ce_loss_value.item())\n",
        "        # print(\"kmeans_loss\", kmeans_weight * kmeans_loss_value.item())\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        sup_loss += ce_loss_value\n",
        "\n",
        "    return total_loss / (len(dataloader.dataset)), (total_loss - sup_loss) / (len(dataloader.dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUL9zLZSVhf7"
      },
      "source": [
        "### Definition of `training_combined_complete()`\n",
        "This function uses Resnet-Kmeans training method. `label_ratio` is the ratio of labeled data to entire CIFAR-10 training data, `save_model` decide if save final best model and `identify` is for customizing the name of saved model. The name will be `best_sup_kmeans_model_{identify}.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbugDpkuRc1n"
      },
      "outputs": [],
      "source": [
        "def training_combined_complete(label_ratio, save_model=True, identify=\"\"):\n",
        "    stop_threshold = 3\n",
        "\n",
        "    dataloader = CIFARData(batch_size=BATCHES, num_workers=WORKERS, label_ratio=label_ratio)\n",
        "    label_data = dataloader.labeled_train_loader\n",
        "    unlabeled_data = dataloader.unlabeled_train_loader\n",
        "    test_data = dataloader.test_loader\n",
        "\n",
        "    # get supervised model\n",
        "    sup_resnet, _ = getBestTeacher(True, label_data, test_data)\n",
        "\n",
        "    # initial variables for training loop\n",
        "    stop_count = 0\n",
        "    count = 0\n",
        "\n",
        "    # collect the best accuracy and model\n",
        "    best_model = None\n",
        "    best_train_loss = torch.inf\n",
        "    best_test_loss = torch.inf\n",
        "    best_accuracy = 0\n",
        "\n",
        "    combined_data = CombinedDataset(label_data, unlabeled_data)\n",
        "    combined_dataloader = torch.utils.data.DataLoader(combined_data, batch_size=BATCHES, shuffle=True, num_workers=WORKERS)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(sup_resnet.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(1, EPOCHES + 1):\n",
        "        train_loss, km_loss = train_combined(sup_resnet, combined_dataloader, optimizer, criterion, DEVICE, kmeans_weight=0.005, num_classes=10)\n",
        "\n",
        "        print(\"kmeans loss: \", km_loss.item())\n",
        "        print(\"mean total loss\", train_loss)\n",
        "        test_loss, accuracy = test(sup_resnet, test_data, criterion)\n",
        "      \n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = copy.deepcopy(sup_resnet)\n",
        "            stop_count = 0\n",
        "        else:\n",
        "            stop_count += 1\n",
        "\n",
        "        if stop_count >= stop_threshold:\n",
        "            break\n",
        "\n",
        "    print(\"Best accuracy is {}%\".format(best_accuracy))\n",
        "\n",
        "    if save_model:\n",
        "        if identify == \"\":\n",
        "          identify = str(label_ratio)\n",
        "\n",
        "        sup_kmeans_path = os.path.join(MODEL_SAVE_PATH, \"best_sup_kmeans_model_{},pt\".format(identify))\n",
        "        find_save = os.path.exists(sup_kmeans_path)\n",
        "        state = {\n",
        "            \"model\": best_model.state_dict(), \n",
        "            \"train_loss\": best_train_loss,\n",
        "            \"test_loss\": best_test_loss,\n",
        "            \"accuracy\": best_accuracy\n",
        "        }\n",
        "\n",
        "        # check if we have model saved. if does, compare the accuracy and save the best one\n",
        "        if (find_save):\n",
        "            checkpoint = torch.load(sup_kmeans_path)\n",
        "            saved_acc = checkpoint[\"accuracy\"]\n",
        "            if (best_accuracy > saved_acc):\n",
        "                torch.save(state, sup_kmeans_path)\n",
        "        else:\n",
        "            torch.save(state, sup_kmeans_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36K7eANBhYHr"
      },
      "source": [
        "### Try Resnet-Kmeans method with `label_ratio=0.01`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLfDwL0dow6k"
      },
      "source": [
        "Since for label_ratio = 0.01, the size of labeled data is too small, and thus we changed the batch from 100 to 10 for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWKwUbaPhVGd",
        "outputId": "378133d6-ce6a-4a14-df4a-aa4039ea800f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.1810344316959381\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.1988, Accuracy: 2844/10000 (28.4%)\n",
            "\n",
            "kmeans loss:  0.11205468326807022\n",
            "mean total loss 0.13412679216504098\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2291, Accuracy: 1000/10000 (10.0%)\n",
            "\n",
            "kmeans loss:  0.1114158183336258\n",
            "mean total loss 0.13328301885008811\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2214, Accuracy: 1713/10000 (17.1%)\n",
            "\n",
            "kmeans loss:  0.11146499961614609\n",
            "mean total loss 0.1331779912483692\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2247, Accuracy: 1501/10000 (15.0%)\n",
            "\n",
            "kmeans loss:  0.11152375489473343\n",
            "mean total loss 0.13283682131528854\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2198, Accuracy: 1848/10000 (18.5%)\n",
            "\n",
            "kmeans loss:  0.1115003451704979\n",
            "mean total loss 0.13245701295137405\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2169, Accuracy: 1650/10000 (16.5%)\n",
            "\n",
            "kmeans loss:  0.11157429218292236\n",
            "mean total loss 0.1327523038136959\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2172, Accuracy: 1856/10000 (18.6%)\n",
            "\n",
            "kmeans loss:  0.11150214821100235\n",
            "mean total loss 0.13205820820808412\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2165, Accuracy: 1705/10000 (17.0%)\n",
            "\n",
            "kmeans loss:  0.11147487908601761\n",
            "mean total loss 0.13248853794813156\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2084, Accuracy: 1980/10000 (19.8%)\n",
            "\n",
            "kmeans loss:  0.11138108372688293\n",
            "mean total loss 0.13165606407523156\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2072, Accuracy: 1881/10000 (18.8%)\n",
            "\n",
            "kmeans loss:  0.11142230033874512\n",
            "mean total loss 0.1317685663127899\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2100, Accuracy: 1973/10000 (19.7%)\n",
            "\n",
            "kmeans loss:  0.11149529367685318\n",
            "mean total loss 0.1319421228504181\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.2137, Accuracy: 1740/10000 (17.4%)\n",
            "\n",
            "Best accuracy is 19.799999237060547%\n"
          ]
        }
      ],
      "source": [
        "EPOCHES = 200\n",
        "BATCHES = 10\n",
        "training_combined_complete(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfATV3-ul89M"
      },
      "source": [
        "### Try Resnet-Kmeans method with `label_ratio=0.05`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUnRgGtzl0EJ",
        "outputId": "ac3598c6-e9aa-4c29-ca8d-f5be94889509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.012524021005630492\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0187, Accuracy: 4220/10000 (42.2%)\n",
            "\n",
            "kmeans loss:  0.013210974633693695\n",
            "mean total loss 0.03188006302595139\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0176, Accuracy: 3620/10000 (36.2%)\n",
            "\n",
            "kmeans loss:  0.01186029240489006\n",
            "mean total loss 0.03007884806871414\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0187, Accuracy: 3135/10000 (31.3%)\n",
            "\n",
            "kmeans loss:  0.011784980073571205\n",
            "mean total loss 0.028924771864414216\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0191, Accuracy: 3423/10000 (34.2%)\n",
            "\n",
            "kmeans loss:  0.011711805127561092\n",
            "mean total loss 0.028062045946121217\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0173, Accuracy: 3777/10000 (37.8%)\n",
            "\n",
            "kmeans loss:  0.011683761142194271\n",
            "mean total loss 0.02784132297039032\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0160, Accuracy: 4225/10000 (42.2%)\n",
            "\n",
            "kmeans loss:  0.011631540022790432\n",
            "mean total loss 0.027149846224784852\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0198, Accuracy: 3718/10000 (37.2%)\n",
            "\n",
            "kmeans loss:  0.011577975004911423\n",
            "mean total loss 0.02682139134168625\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0180, Accuracy: 3714/10000 (37.1%)\n",
            "\n",
            "kmeans loss:  0.011548393405973911\n",
            "mean total loss 0.0265929146027565\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0166, Accuracy: 4243/10000 (42.4%)\n",
            "\n",
            "kmeans loss:  0.01156601496040821\n",
            "mean total loss 0.026141371147632597\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0161, Accuracy: 4336/10000 (43.4%)\n",
            "\n",
            "kmeans loss:  0.0115134809166193\n",
            "mean total loss 0.0257618275141716\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0168, Accuracy: 4232/10000 (42.3%)\n",
            "\n",
            "kmeans loss:  0.011491077952086926\n",
            "mean total loss 0.025766206328868866\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0148, Accuracy: 4837/10000 (48.4%)\n",
            "\n",
            "kmeans loss:  0.01151726022362709\n",
            "mean total loss 0.025663204889297485\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0149, Accuracy: 4833/10000 (48.3%)\n",
            "\n",
            "kmeans loss:  0.011487461626529694\n",
            "mean total loss 0.025202868447303774\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0181, Accuracy: 4385/10000 (43.8%)\n",
            "\n",
            "kmeans loss:  0.011513990350067616\n",
            "mean total loss 0.025143240320682526\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0163, Accuracy: 4519/10000 (45.2%)\n",
            "\n",
            "Best accuracy is 48.369998931884766%\n"
          ]
        }
      ],
      "source": [
        "BATCHES = 100\n",
        "training_combined_complete(0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKYh5SBOc8t2"
      },
      "source": [
        "### Try Resnet-Kmeans method with `label_ratio=0.1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWhAJ5eiAWsr",
        "outputId": "912e3274-a11d-4e2d-b6d7-ced2bddee905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.011213637590408325\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0149, Accuracy: 5143/10000 (51.4%)\n",
            "\n",
            "kmeans loss:  0.013871223796606064\n",
            "mean total loss 0.02940688495159149\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0163, Accuracy: 4194/10000 (41.9%)\n",
            "\n",
            "kmeans loss:  0.012064727804660797\n",
            "mean total loss 0.026774258503913878\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0163, Accuracy: 4270/10000 (42.7%)\n",
            "\n",
            "kmeans loss:  0.011999425902366637\n",
            "mean total loss 0.02592028670310974\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0141, Accuracy: 5017/10000 (50.2%)\n",
            "\n",
            "kmeans loss:  0.01183801806807518\n",
            "mean total loss 0.025365704154968263\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0159, Accuracy: 4622/10000 (46.2%)\n",
            "\n",
            "kmeans loss:  0.011731093353629112\n",
            "mean total loss 0.024943837697505952\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0152, Accuracy: 4657/10000 (46.6%)\n",
            "\n",
            "kmeans loss:  0.011698974598646165\n",
            "mean total loss 0.02447848507642746\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0140, Accuracy: 5193/10000 (51.9%)\n",
            "\n",
            "kmeans loss:  0.011630386663079261\n",
            "mean total loss 0.024116264719963074\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0168, Accuracy: 4724/10000 (47.2%)\n",
            "\n",
            "kmeans loss:  0.011618952551484108\n",
            "mean total loss 0.023851243288517\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0143, Accuracy: 5124/10000 (51.2%)\n",
            "\n",
            "kmeans loss:  0.01157121157437563\n",
            "mean total loss 0.023436423709392546\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0131, Accuracy: 5339/10000 (53.4%)\n",
            "\n",
            "kmeans loss:  0.011577976111769675\n",
            "mean total loss 0.02321698955774307\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0136, Accuracy: 5238/10000 (52.4%)\n",
            "\n",
            "kmeans loss:  0.01158805227637291\n",
            "mean total loss 0.02317318197488785\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0138, Accuracy: 5430/10000 (54.3%)\n",
            "\n",
            "kmeans loss:  0.011515277948528527\n",
            "mean total loss 0.02273223386526108\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0131, Accuracy: 5552/10000 (55.5%)\n",
            "\n",
            "kmeans loss:  0.011498943009376527\n",
            "mean total loss 0.022661281526088716\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0142, Accuracy: 5255/10000 (52.5%)\n",
            "\n",
            "kmeans loss:  0.011472347760498524\n",
            "mean total loss 0.022274503979682923\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0131, Accuracy: 5593/10000 (55.9%)\n",
            "\n",
            "kmeans loss:  0.011487232374548913\n",
            "mean total loss 0.022089138796329497\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0140, Accuracy: 5500/10000 (55.0%)\n",
            "\n",
            "kmeans loss:  0.01146297546453774\n",
            "mean total loss 0.0219386190700531\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0131, Accuracy: 5603/10000 (56.0%)\n",
            "\n",
            "kmeans loss:  0.011428655802309513\n",
            "mean total loss 0.021843727819919587\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0134, Accuracy: 5721/10000 (57.2%)\n",
            "\n",
            "kmeans loss:  0.011440960227549077\n",
            "mean total loss 0.02164094815969467\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0124, Accuracy: 5835/10000 (58.3%)\n",
            "\n",
            "kmeans loss:  0.01148587865382433\n",
            "mean total loss 0.021212034826278686\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0139, Accuracy: 5442/10000 (54.4%)\n",
            "\n",
            "kmeans loss:  0.011435311081111432\n",
            "mean total loss 0.021248567762374878\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0124, Accuracy: 5843/10000 (58.4%)\n",
            "\n",
            "kmeans loss:  0.01143856594502926\n",
            "mean total loss 0.021008327205181122\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0143, Accuracy: 5461/10000 (54.6%)\n",
            "\n",
            "kmeans loss:  0.011423303916454314\n",
            "mean total loss 0.02086644228219986\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0130, Accuracy: 5693/10000 (56.9%)\n",
            "\n",
            "kmeans loss:  0.011422861871868372\n",
            "mean total loss 0.02054340914487839\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0126, Accuracy: 5869/10000 (58.7%)\n",
            "\n",
            "kmeans loss:  0.011437860710024833\n",
            "mean total loss 0.020402741844654085\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0129, Accuracy: 5935/10000 (59.3%)\n",
            "\n",
            "kmeans loss:  0.011403531361818313\n",
            "mean total loss 0.020429601736068725\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0153, Accuracy: 5393/10000 (53.9%)\n",
            "\n",
            "kmeans loss:  0.011373887408673762\n",
            "mean total loss 0.02021992889404297\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0153, Accuracy: 5532/10000 (55.3%)\n",
            "\n",
            "kmeans loss:  0.011376219692379235\n",
            "mean total loss 0.020078224148750306\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0126, Accuracy: 5955/10000 (59.5%)\n",
            "\n",
            "kmeans loss:  0.011379066600389778\n",
            "mean total loss 0.019900304272174835\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0124, Accuracy: 6121/10000 (61.2%)\n",
            "\n",
            "kmeans loss:  0.011323113223016263\n",
            "mean total loss 0.019810718476772307\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0141, Accuracy: 5796/10000 (58.0%)\n",
            "\n",
            "kmeans loss:  0.011372192560434341\n",
            "mean total loss 0.019571390216350557\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0152, Accuracy: 5507/10000 (55.1%)\n",
            "\n",
            "kmeans loss:  0.011414843440651894\n",
            "mean total loss 0.019375637969970702\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0132, Accuracy: 5908/10000 (59.1%)\n",
            "\n",
            "Best accuracy is 61.209999084472656%\n"
          ]
        }
      ],
      "source": [
        "training_combined_complete(0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj9osmJsdBsZ"
      },
      "source": [
        "### Try Resnet-Kmeans method with `label_ratio=0.3`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l5ZFEohDnfM",
        "outputId": "905ee787-7eb8-4994-c71b-ceb01981cb40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.008352892430623373\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0107, Accuracy: 6553/10000 (65.5%)\n",
            "\n",
            "kmeans loss:  0.014212156769037247\n",
            "mean total loss 0.024162908594608307\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0120, Accuracy: 6061/10000 (60.6%)\n",
            "\n",
            "kmeans loss:  0.012182199214696885\n",
            "mean total loss 0.021831735804080963\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0106, Accuracy: 6422/10000 (64.2%)\n",
            "\n",
            "kmeans loss:  0.01187744814157486\n",
            "mean total loss 0.021088672134876252\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0126, Accuracy: 5912/10000 (59.1%)\n",
            "\n",
            "kmeans loss:  0.011737910906672477\n",
            "mean total loss 0.02075994631767273\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0137, Accuracy: 5658/10000 (56.6%)\n",
            "\n",
            "kmeans loss:  0.011645719663500786\n",
            "mean total loss 0.020482404303550722\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0111, Accuracy: 6462/10000 (64.6%)\n",
            "\n",
            "kmeans loss:  0.011621889114379882\n",
            "mean total loss 0.020100606570243835\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0120, Accuracy: 6242/10000 (62.4%)\n",
            "\n",
            "kmeans loss:  0.011603143510818481\n",
            "mean total loss 0.019798310236930846\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0106, Accuracy: 6619/10000 (66.2%)\n",
            "\n",
            "kmeans loss:  0.011495973855257035\n",
            "mean total loss 0.019583072867393494\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0106, Accuracy: 6611/10000 (66.1%)\n",
            "\n",
            "kmeans loss:  0.011494519879817963\n",
            "mean total loss 0.019325078032016753\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0116, Accuracy: 6489/10000 (64.9%)\n",
            "\n",
            "kmeans loss:  0.011497993957996368\n",
            "mean total loss 0.019184868397712707\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0100, Accuracy: 6805/10000 (68.0%)\n",
            "\n",
            "kmeans loss:  0.011424786613583565\n",
            "mean total loss 0.01887276099920273\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0097, Accuracy: 6890/10000 (68.9%)\n",
            "\n",
            "kmeans loss:  0.011452190034389496\n",
            "mean total loss 0.01879042624950409\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0095, Accuracy: 6933/10000 (69.3%)\n",
            "\n",
            "kmeans loss:  0.011445848776102066\n",
            "mean total loss 0.018709288773536684\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0095, Accuracy: 7019/10000 (70.2%)\n",
            "\n",
            "kmeans loss:  0.011390806757211686\n",
            "mean total loss 0.018383009099960327\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0090, Accuracy: 7134/10000 (71.3%)\n",
            "\n",
            "kmeans loss:  0.01144068738669157\n",
            "mean total loss 0.01837031695842743\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0089, Accuracy: 7236/10000 (72.4%)\n",
            "\n",
            "kmeans loss:  0.011422213085293769\n",
            "mean total loss 0.018153523128032683\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0100, Accuracy: 6943/10000 (69.4%)\n",
            "\n",
            "kmeans loss:  0.011387278358638286\n",
            "mean total loss 0.017987265648841858\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0104, Accuracy: 6901/10000 (69.0%)\n",
            "\n",
            "kmeans loss:  0.011351921817958355\n",
            "mean total loss 0.017942154443264007\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0101, Accuracy: 6898/10000 (69.0%)\n",
            "\n",
            "Best accuracy is 72.36000061035156%\n"
          ]
        }
      ],
      "source": [
        "training_combined_complete(0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2MbEK2ldI5J"
      },
      "source": [
        "### Try Resnet-Kmeans method with `label_ratio=0.5`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSQoSauuPmFY",
        "outputId": "785ba906-99ef-4a97-89f9-bcd50f19d9f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher starts to be trained with labeled data...\n",
            "Loss on the training data: 0.007031093447208404\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0087, Accuracy: 7138/10000 (71.4%)\n",
            "\n",
            "kmeans loss:  0.013681236841082573\n",
            "mean total loss 0.021717731413841247\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0098, Accuracy: 6738/10000 (67.4%)\n",
            "\n",
            "kmeans loss:  0.012058525638580323\n",
            "mean total loss 0.01987470884799957\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0091, Accuracy: 6932/10000 (69.3%)\n",
            "\n",
            "kmeans loss:  0.011792267298102378\n",
            "mean total loss 0.019187329194545747\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0096, Accuracy: 6889/10000 (68.9%)\n",
            "\n",
            "kmeans loss:  0.011680267489552499\n",
            "mean total loss 0.018931614379882812\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0096, Accuracy: 6862/10000 (68.6%)\n",
            "\n",
            "kmeans loss:  0.011607055541276931\n",
            "mean total loss 0.018577202091217042\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0093, Accuracy: 6995/10000 (69.9%)\n",
            "\n",
            "kmeans loss:  0.01153370698094368\n",
            "mean total loss 0.018296331706047057\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0088, Accuracy: 7132/10000 (71.3%)\n",
            "\n",
            "kmeans loss:  0.011467293034791947\n",
            "mean total loss 0.01806046597480774\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0088, Accuracy: 7194/10000 (71.9%)\n",
            "\n",
            "kmeans loss:  0.011531403672695159\n",
            "mean total loss 0.0180022389960289\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0083, Accuracy: 7255/10000 (72.5%)\n",
            "\n",
            "kmeans loss:  0.011436995137929916\n",
            "mean total loss 0.017833178470134735\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0084, Accuracy: 7281/10000 (72.8%)\n",
            "\n",
            "kmeans loss:  0.011414608201384544\n",
            "mean total loss 0.017645876643657684\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0088, Accuracy: 7149/10000 (71.5%)\n",
            "\n",
            "kmeans loss:  0.011459111036062241\n",
            "mean total loss 0.017528849108219148\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0089, Accuracy: 7200/10000 (72.0%)\n",
            "\n",
            "kmeans loss:  0.011407444754242897\n",
            "mean total loss 0.01726671201467514\n",
            "Testing starts...\n",
            "Test result - Average loss: 0.0090, Accuracy: 7144/10000 (71.4%)\n",
            "\n",
            "Best accuracy is 72.80999755859375%\n"
          ]
        }
      ],
      "source": [
        "training_combined_complete(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttfT84060054"
      },
      "source": [
        "# Result and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir-Pk6M7LiYU"
      },
      "source": [
        "## Table and plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzsJ0T6LH_3k"
      },
      "source": [
        "Using outcomes of the experiment, we generate a table and two plots to display the outcomes for both 2 methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5pQ2r3dDLpFk",
        "outputId": "67f506ea-0798-4e57-b7d8-db5d5df395a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_03e12 th {\n",
              "  background-color: #4CAF50;\n",
              "  color: white;\n",
              "}\n",
              "#T_03e12 tbody tr:nth-child(even) {\n",
              "  background-color: #f2f2f2;\n",
              "}\n",
              "#T_03e12 tbody tr:nth-child(odd) {\n",
              "  background-color: white;\n",
              "}\n",
              "#T_03e12_row0_col0, #T_03e12_row0_col1, #T_03e12_row0_col2, #T_03e12_row0_col3, #T_03e12_row0_col4, #T_03e12_row1_col0, #T_03e12_row1_col1, #T_03e12_row1_col2, #T_03e12_row1_col3, #T_03e12_row1_col4, #T_03e12_row2_col0, #T_03e12_row2_col1, #T_03e12_row2_col2, #T_03e12_row2_col3, #T_03e12_row2_col4, #T_03e12_row3_col0, #T_03e12_row3_col1, #T_03e12_row3_col2, #T_03e12_row3_col3, #T_03e12_row3_col4, #T_03e12_row4_col0, #T_03e12_row4_col1, #T_03e12_row4_col2, #T_03e12_row4_col3, #T_03e12_row4_col4, #T_03e12_row5_col0, #T_03e12_row5_col1, #T_03e12_row5_col2, #T_03e12_row5_col3, #T_03e12_row6_col0, #T_03e12_row6_col1, #T_03e12_row6_col2, #T_03e12_row6_col3, #T_03e12_row7_col0, #T_03e12_row7_col1, #T_03e12_row7_col2, #T_03e12_row7_col3, #T_03e12_row8_col0, #T_03e12_row8_col1, #T_03e12_row8_col2, #T_03e12_row8_col3, #T_03e12_row9_col0, #T_03e12_row9_col1, #T_03e12_row9_col2, #T_03e12_row9_col3 {\n",
              "  border: 1px solid black;\n",
              "  text-align: center;\n",
              "  font-size: 14px;\n",
              "  padding: 4px 8px;\n",
              "}\n",
              "#T_03e12_row5_col4, #T_03e12_row6_col4, #T_03e12_row7_col4, #T_03e12_row8_col4, #T_03e12_row9_col4 {\n",
              "  background-color: #f2f2f2;\n",
              "  border: 1px solid black;\n",
              "  text-align: center;\n",
              "  font-size: 14px;\n",
              "  padding: 4px 8px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_03e12\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_03e12_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
              "      <th id=\"T_03e12_level0_col1\" class=\"col_heading level0 col1\" >Label Ratio</th>\n",
              "      <th id=\"T_03e12_level0_col2\" class=\"col_heading level0 col2\" >Initial Accuracy</th>\n",
              "      <th id=\"T_03e12_level0_col3\" class=\"col_heading level0 col3\" >Final Accuracy</th>\n",
              "      <th id=\"T_03e12_level0_col4\" class=\"col_heading level0 col4\" >Final Label Data Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_03e12_row0_col0\" class=\"data row0 col0\" >Pseudo-labelling</td>\n",
              "      <td id=\"T_03e12_row0_col1\" class=\"data row0 col1\" >0.010000</td>\n",
              "      <td id=\"T_03e12_row0_col2\" class=\"data row0 col2\" >31.600000</td>\n",
              "      <td id=\"T_03e12_row0_col3\" class=\"data row0 col3\" >37.400000</td>\n",
              "      <td id=\"T_03e12_row0_col4\" class=\"data row0 col4\" >6949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_03e12_row1_col0\" class=\"data row1 col0\" >Pseudo-labelling</td>\n",
              "      <td id=\"T_03e12_row1_col1\" class=\"data row1 col1\" >0.050000</td>\n",
              "      <td id=\"T_03e12_row1_col2\" class=\"data row1 col2\" >44.500000</td>\n",
              "      <td id=\"T_03e12_row1_col3\" class=\"data row1 col3\" >53.100000</td>\n",
              "      <td id=\"T_03e12_row1_col4\" class=\"data row1 col4\" >5948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_03e12_row2_col0\" class=\"data row2 col0\" >Pseudo-labelling</td>\n",
              "      <td id=\"T_03e12_row2_col1\" class=\"data row2 col1\" >0.100000</td>\n",
              "      <td id=\"T_03e12_row2_col2\" class=\"data row2 col2\" >53.900000</td>\n",
              "      <td id=\"T_03e12_row2_col3\" class=\"data row2 col3\" >61.800000</td>\n",
              "      <td id=\"T_03e12_row2_col4\" class=\"data row2 col4\" >15679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_03e12_row3_col0\" class=\"data row3 col0\" >Pseudo-labelling</td>\n",
              "      <td id=\"T_03e12_row3_col1\" class=\"data row3 col1\" >0.300000</td>\n",
              "      <td id=\"T_03e12_row3_col2\" class=\"data row3 col2\" >61.800000</td>\n",
              "      <td id=\"T_03e12_row3_col3\" class=\"data row3 col3\" >71.100000</td>\n",
              "      <td id=\"T_03e12_row3_col4\" class=\"data row3 col4\" >27254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_03e12_row4_col0\" class=\"data row4 col0\" >Pseudo-labelling</td>\n",
              "      <td id=\"T_03e12_row4_col1\" class=\"data row4 col1\" >0.500000</td>\n",
              "      <td id=\"T_03e12_row4_col2\" class=\"data row4 col2\" >66.600000</td>\n",
              "      <td id=\"T_03e12_row4_col3\" class=\"data row4 col3\" >73.600000</td>\n",
              "      <td id=\"T_03e12_row4_col4\" class=\"data row4 col4\" >29849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_03e12_row5_col0\" class=\"data row5 col0\" >Resnet-Kmeans</td>\n",
              "      <td id=\"T_03e12_row5_col1\" class=\"data row5 col1\" >0.010000</td>\n",
              "      <td id=\"T_03e12_row5_col2\" class=\"data row5 col2\" >28.400000</td>\n",
              "      <td id=\"T_03e12_row5_col3\" class=\"data row5 col3\" >19.800000</td>\n",
              "      <td id=\"T_03e12_row5_col4\" class=\"data row5 col4\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_03e12_row6_col0\" class=\"data row6 col0\" >Resnet-Kmeans</td>\n",
              "      <td id=\"T_03e12_row6_col1\" class=\"data row6 col1\" >0.050000</td>\n",
              "      <td id=\"T_03e12_row6_col2\" class=\"data row6 col2\" >42.200000</td>\n",
              "      <td id=\"T_03e12_row6_col3\" class=\"data row6 col3\" >48.400000</td>\n",
              "      <td id=\"T_03e12_row6_col4\" class=\"data row6 col4\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_03e12_row7_col0\" class=\"data row7 col0\" >Resnet-Kmeans</td>\n",
              "      <td id=\"T_03e12_row7_col1\" class=\"data row7 col1\" >0.100000</td>\n",
              "      <td id=\"T_03e12_row7_col2\" class=\"data row7 col2\" >51.400000</td>\n",
              "      <td id=\"T_03e12_row7_col3\" class=\"data row7 col3\" >61.200000</td>\n",
              "      <td id=\"T_03e12_row7_col4\" class=\"data row7 col4\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_03e12_row8_col0\" class=\"data row8 col0\" >Resnet-Kmeans</td>\n",
              "      <td id=\"T_03e12_row8_col1\" class=\"data row8 col1\" >0.300000</td>\n",
              "      <td id=\"T_03e12_row8_col2\" class=\"data row8 col2\" >65.500000</td>\n",
              "      <td id=\"T_03e12_row8_col3\" class=\"data row8 col3\" >72.400000</td>\n",
              "      <td id=\"T_03e12_row8_col4\" class=\"data row8 col4\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_03e12_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_03e12_row9_col0\" class=\"data row9 col0\" >Resnet-Kmeans</td>\n",
              "      <td id=\"T_03e12_row9_col1\" class=\"data row9 col1\" >0.500000</td>\n",
              "      <td id=\"T_03e12_row9_col2\" class=\"data row9 col2\" >71.400000</td>\n",
              "      <td id=\"T_03e12_row9_col3\" class=\"data row9 col3\" >72.800000</td>\n",
              "      <td id=\"T_03e12_row9_col4\" class=\"data row9 col4\" >-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fdfb89daf40>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = [['Pseudo-labelling', 0.01, 31.6, 37.4, 6949],\n",
        "        ['Pseudo-labelling', 0.05, 44.5, 53.1, 5948],\n",
        "        ['Pseudo-labelling', 0.1, 53.9, 61.8, 15679],\n",
        "        ['Pseudo-labelling', 0.3, 61.8, 71.1, 27254],\n",
        "        ['Pseudo-labelling', 0.5, 66.6, 73.6, 29849],\n",
        "        ['Resnet-Kmeans', 0.01, 28.4, 19.8, '-'],\n",
        "        ['Resnet-Kmeans', 0.05, 42.2, 48.4, '-'],\n",
        "        ['Resnet-Kmeans', 0.1, 51.4, 61.2, '-'],\n",
        "        ['Resnet-Kmeans', 0.3, 65.5, 72.4, '-'],\n",
        "        ['Resnet-Kmeans', 0.5, 71.4, 72.8, '-']]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Method', 'Label Ratio', 'Initial Accuracy', 'Final Accuracy', 'Final Label Data Size'])\n",
        "\n",
        "styled_df = df.style.applymap(lambda x: 'background-color: #f2f2f2' if x == '-' else '')\n",
        "\n",
        "styled_df = styled_df.set_properties(**{'border': '1px solid black', 'text-align': 'center', 'font-size': '14px', 'padding': '4px 8px'})\n",
        "\n",
        "styled_df = styled_df.set_table_styles([{\n",
        "    'selector': 'th',\n",
        "    'props': [('background-color', '#4CAF50'), ('color', 'white')]\n",
        "    },\n",
        "    {\n",
        "    'selector': 'tbody tr:nth-child(even)',\n",
        "    'props': [('background-color', '#f2f2f2')]\n",
        "    },\n",
        "    {\n",
        "    'selector': 'tbody tr:nth-child(odd)',\n",
        "    'props': [('background-color', 'white')]\n",
        "    }])\n",
        "\n",
        "display(styled_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "YI0rGFEUpdk7",
        "outputId": "7cd041f6-ee12-4b32-9da5-b225f3415e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<pandas.io.formats.style.Styler object at 0x7fe080189c10>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['Increased Accuracy'] = df['Final Accuracy'] - df['Initial Accuracy']\n",
        "df1 = df[df['Method']=='Pseudo-labelling']\n",
        "df2 = df[df['Method']=='Resnet-Kmeans']\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "axs[0].plot(df1['Label Ratio'], df1['Final Accuracy'], label='Pseudo-labelling: Final Accuracy')\n",
        "axs[0].plot(df2['Label Ratio'], df2['Final Accuracy'], label='Resnet-Kmeans: Final Accuracy')\n",
        "axs[0].set_xlabel('Label Ratio')\n",
        "axs[0].set_ylabel('Final Accuracy')\n",
        "axs[0].set_title('Final Accuracy vs Label Ratio')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(df1['Label Ratio'], df1['Increased Accuracy'], label='Pseudo-labelling')\n",
        "axs[1].plot(df2['Label Ratio'], df2['Increased Accuracy'], label='Resnet-Kmeans')\n",
        "axs[1].set_xlabel('Label Ratio')\n",
        "axs[1].set_ylabel('Increased Accuracy')\n",
        "axs[1].set_title('Increased Accuracy vs Label Ratio')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52gjUv03Dpr7"
      },
      "source": [
        "## Pseudo-Labelling\n",
        "In the results and discussion section, we first analyze the performance of the Pseudo-labelling model. Regardless of the label_ratio settings, the final accuracy is consistently higher than the initial accuracy. As illustrated in the increased accuracy graph, the improvement in accuracy remains relatively stable at around 7.5% and exhibits an overall trend of first increasing and then decreasing. This implies that when the label ratio is low, the effect of pseudo-labeling is not optimal. As the label ratio increases, the improvement in accuracy generally rises. However, as the initial accuracy increases, the model's performance gradually approaches the best performance achievable using all data (75%-80%), thus leaving less room for improvement. Consequently, when the label ratio is 0.5, using pseudo-labelling results in an accuracy improvement of only 7%. Furthermore, the change in the labeled dataset's size is not directly correlated with the model's performance due to the quality of pseudo-labels. By comparing the cases where label_ratio is 0.01 and 0.05, we can observe that with a label_ratio of 0.1, pseudo-labelling adds a significant amount of labeled data, even more than when the label_ratio is 0.05, but the performance improvement is not outstanding. In addition, when label_ratio is 0.5, although only adding less than 5,000 labeled data points, the model's performance improves considerably."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oQ7JqQxD5L8"
      },
      "source": [
        "## Resnet-Kmeans\n",
        "Next, we examine the results of the ResNet-KMeans model. . However, the results reveal an issue: when label_ratio is 0.01, the ResNet-KMeans model does not perform well, even leading to a decline in performance. This issue was considered during our initial experiment and contributed to our adoption of the current model structure. In the present structure, the KMeans clustering loss is combined only after obtaining a trained ResNet, whereas the previous structure combined the KMeans clustering loss from the outset. The performance of the earlier model was significantly poorer, and the KMeans clustering loss hardly converged. We considered whether inappropriate learning rates, KMeans loss weights, initial centroids, or model complexity caused this issue, but after extensive testing and deliberation, we identified the problem. When training begins, the model performs poorly, resulting in weak deep feature representation capabilities. This implies that, at this stage, combining the KMeans clustering loss with cross-entropy is not meaningful and may even have adverse effects. Taking this issue into account, we modified the structure, allowing KMeans to be incorporated into training after the initial ResNet training. Although the new structure resolves the aforementioned issue, when the label ratio is extremely low, the model's performance remains poor even after initial training, rendering KMeans ineffective. This issue is absent when label_ratio is 0.05 or higher. Furthermore, we note that the improvement in accuracy in the ResNet-KMeans model also exhibits an overall trend of first increasing and then decreasing, with the highest increase at label_ratio 0.1. When label_ratio is 0.5, the improvement is minimal, possibly due to limited room for improvement caused by a higher initial accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu3HjrArEUac"
      },
      "source": [
        "## Comparison\n",
        "Comparing both models, it is evident that the initial accuracies are generally similar across different label_ratios, as both methods employ the same supervised model (ResNet) structure, albeit influenced by randomness. The overall trend in accuracy improvement for both models is similar, with the improvement first increasing and then decreasing. The ResNet-KMeans model demonstrated slightly lower final accuracy than the Pseudo-labelling model. However, it is important to note that the training time for the ResNet-KMeans model was significantly shorter, as it only required one initial supervised model training and single-epoch iterations in subsequent steps.\n",
        "\n",
        "Another aspect to consider in the comparison is the stability and consistency of the models. While Pseudo-labelling exhibited a more stable accuracy improvement across different label_ratios, the ResNet-KMeans model showed more variation, particularly struggling at extremely low label_ratios. Additionally, the impact of the quality of pseudo-labels on Pseudo-labelling performance and the limitations of ResNet-KMeans due to poor deep feature representation capabilities at low label_ratios highlight the specific challenges each model faces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCjidLJT053G"
      },
      "source": [
        "# Conclusion\n",
        "In conclusion, both Pseudo-labelling and ResNet-KMeans models offer unique advantages and face certain limitations in semi-supervised learning. Pseudo-labelling provides consistent accuracy improvements across varying label_ratios but may require more computational resources due to the need to train a new supervised model in each iteration. On the other hand, the ResNet-KMeans model can achieve substantial accuracy improvements at higher label_ratios and offers a more efficient training process but may struggle with extremely low label_ratios.\n",
        "\n",
        "The choice between these two approaches should be based on the specific requirements and constraints of a given problem and the available resources. It is crucial to consider factors such as computational efficiency, model stability, and performance consistency when selecting the appropriate semi-supervised learning model for a particular task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOvvzVvHuel"
      },
      "source": [
        "# Future Study\n",
        "\n",
        "In this study, due to time constraints and the focus on utilizing unlabeled data to improve model performance, our exploration of the supervised model structures might not have been exhaustive, and the models used might not be optimal. If given more time, we would attempt to further explore various model structures to achieve better performance. Additionally, we could perform multiple training runs for each label_ratio and take the average results to obtain more reliable outcomes.\n",
        "\n",
        "Moreover, future research may investigate a broader range of semi-supervised learning model structures and examine the performance of different loss functions in this context. This study's time limitations also prevented us from thoroughly tuning the threshold for generating pseudo-labels and other hyperparameters, such as learning rate and batch size. Although we manually adjusted these parameters in several iterations, they might not be the best choices. Therefore, future studies could dedicate more time to hyperparameter tuning and optimization to enhance model performance.\n",
        "\n",
        "Investigating the impact of different data distributions, noise levels, and data modalities on the performance of Pseudo-labelling and ResNet-KMeans models would also be valuable. Developing hybrid approaches that combine the strengths of both models, or incorporating other techniques such as active learning, could lead to more robust and efficient semi-supervised learning solutions. Finally, evaluating the practical utility and effectiveness of these models in various real-world applications, such as healthcare, finance, and natural language processing, could provide valuable insights into their potential use cases."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
